{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks import UnetEncodeLayer, UnetUpscaleLayer, UnetForwardDecodeLayer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms.v2 import functional\n",
    "class Urnet(nn.Module):\n",
    "      # classic Unet with some reshape and cropping to match our needs.\n",
    "\tdef __init__(self, num_classes):\n",
    "\t\tsuper(Urnet, self).__init__()\n",
    "\t\tself.residuals = []\n",
    "\t\tself.requires_context = False\n",
    "    \t# encoding part of the Unet vanilla architecture\n",
    "\t\tself.encode1 = nn.Sequential(\n",
    "\t\t\tUnetEncodeLayer(3, 64, padding=1),\n",
    "\t\t\tUnetEncodeLayer(64, 64, padding=1), ## keep dimensions unchanged\n",
    "\t\t)\n",
    "\t\tself.encode1_c = nn.Sequential(\n",
    "\t\t\tUnetEncodeLayer(3, 64, padding=1),\n",
    "\t\t\tUnetEncodeLayer(64, 64, padding=1), ## keep dimensions unchanged\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.encode2 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(64, 128, padding=1),\n",
    "\t\t\tUnetEncodeLayer(128, 128, padding=1),\n",
    "\t\t)\t\t\n",
    "\t\tself.encode2_c= nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(64, 128, padding=1),\n",
    "\t\t\tUnetEncodeLayer(128, 128, padding=1),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.encode3 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(128, 256, padding=1),\n",
    "\t\t\tUnetEncodeLayer(256, 256, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode3_c = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(128, 256, padding=1),\n",
    "\t\t\tUnetEncodeLayer(256, 256, padding=1),\n",
    "\t\t)\n",
    "\t\t\n",
    "\n",
    "\t\tself.encode4 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(256, 512, padding=1),\n",
    "\t\t\tUnetEncodeLayer(512, 512, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode4_c = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(256, 512, padding=1),\n",
    "\t\t\tUnetEncodeLayer(512, 512, padding=1),\n",
    "\t\t)\n",
    "\t\t\n",
    "\n",
    "\t\tself.encode5 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(512, 1024, padding=1),\n",
    "\t\t\tUnetEncodeLayer(1024, 1024, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode5_c = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(512, 1024, padding=1),\n",
    "\t\t\tUnetEncodeLayer(1024, 1024, padding=1),\n",
    "\t\t)\n",
    "\t\t\n",
    "\n",
    "\t\tself.upscale1 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2, 1024)\n",
    "\t\t)\n",
    "\t\tself.decode_forward1 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(1024,512, padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale2 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2, 512)\n",
    "\t\t)\n",
    "\t\tself.decode_forward2 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(512, 256, padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale3 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,256)\n",
    "\t\t)\n",
    "\t\tself.decode_forward3 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(256,128,padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale4 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,128)\n",
    "\t\t)\n",
    "\t\tself.decode_forward4 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(128,64, padding=1),\n",
    "\t\t\tnn.Conv2d(64, num_classes, kernel_size=1) # final conv 1x1\n",
    "\t\t\t# Model output is 6xHxW, so we have a prob. distribution\n",
    "\t\t\t# for each pixel (each pixel has a logit for each of the 6 classes.)\n",
    "\t\t)\n",
    "\tdef forward(self, x: torch.Tensor, context=None):\n",
    "\t\tself.x1 = self.encode1(x)\n",
    "\t\tself.x2 = self.encode2(self.x1)\n",
    "\t\tself.x3 = self.encode3(self.x2)\n",
    "\t\tself.x4 = self.encode4(self.x3)\n",
    "\t\tself.x5 = self.encode5(self.x4)\n",
    "\t\t\n",
    "\t\tself.x1_c = self.encode1_c(context)\n",
    "\t\tself.x2_c = self.encode2_c(self.x1)\n",
    "\t\tself.x3_c = self.encode3_c(self.x2)\n",
    "\t\tself.x4_c = self.encode4_c(self.x3)\n",
    "\t\tself.x5_c = self.encode5_c(self.x4)\n",
    "    \n",
    "\t\treturn self.x5, self.x5_c\n",
    "\t\t# y1 = self.upscale1(self.x5)\n",
    "\t\t# c1 = torch.concat((self.x4, y1), 1)\n",
    "\t\t# y2 = self.decode_forward1(c1)\n",
    "\t\t\n",
    "\t\t# y2 = self.upscale2(y2)\n",
    "\t\t# c2 = torch.concat((self.x3, y2), 1)\n",
    "\t\t# y3 = self.decode_forward2(c2)\n",
    "\n",
    "\t\t# y3 = self.upscale3(y3)\n",
    "\t\t# c3 = torch.concat((functional.center_crop(y3, self.x2.shape[2]), self.x2), 1)\n",
    "\t\t# y4 = self.decode_forward3(c3)\n",
    "\n",
    "\t\t# y4 = self.upscale4(y4)\n",
    "\t\t# c4 = torch.concat((self.x1, y4), 1)\n",
    "\t\t# segmap = self.decode_forward4(c4)\n",
    "\t\t#return segmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "test = torch.rand((1,3,224,224))\n",
    "net = Urnet(15)\n",
    "out,out2 = net(test, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
