{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels: int, out_channels: int, padding=0):\n",
    "\treturn nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=padding)\n",
    "\n",
    "\n",
    "def max_pool_2d():\n",
    "\treturn nn.MaxPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetEncodeLayer(nn.Module):\n",
    "    # just a standard convolution layer.\n",
    "\tdef __init__(self, in_channels: int, out_channels: int, activated=True,max_pool=False, padding=0):\n",
    "\t\tsuper(UnetEncodeLayer, self).__init__()\n",
    "\t\tlayers = [\n",
    "            conv3x3(in_channels, out_channels, padding=padding),\n",
    "            # nn.BatchNorm2d(out_channels),\n",
    "        ]\n",
    "\t\tif activated:\n",
    "\t\t\tlayers += [nn.ReLU()]\n",
    "\t\tif max_pool:\n",
    "\t\t\tlayers += [max_pool_2d()]\n",
    "\t\tself.layer = nn.Sequential(*layers)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.layer(x)\n",
    "\t\n",
    "class UnetUpscaleLayer(nn.Module):\n",
    "\tdef __init__(self, scale_factor, in_channels):\n",
    "\t\tsuper(UnetUpscaleLayer, self).__init__()\n",
    "\t\tlayers = [\n",
    "\t\t\tnn.Upsample(scale_factor = (scale_factor,scale_factor), mode = 'bilinear'),\n",
    "\t\t\tconv3x3(in_channels, in_channels//2,padding=1)\n",
    "\t\t]\n",
    "\t\tself.layer = nn.Sequential(*layers)\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.layer(x)\n",
    "\n",
    "class UnetForwardDecodeLayer(nn.Module):\n",
    "\tdef __init__(self, in_channels, out_channels, padding=0):\n",
    "\t\tsuper(UnetForwardDecodeLayer, self).__init__()\n",
    "\t\tlayers = [\n",
    "\t\t\tconv3x3(in_channels=in_channels, out_channels=out_channels, padding=padding),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tconv3x3(in_channels=out_channels, out_channels=out_channels, padding=padding),\n",
    "\t\t\tnn.ReLU()\n",
    "\t\t]\n",
    "\t\tself.layer = nn.Sequential(*layers)\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "+ Still don't know how to handle residuals without creating different sequential modules and use them separately;\n",
    "+ Still need to handle images of our desired dimensions;\n",
    "+ Still need to understand how a 2x2 convolution can leave unchanged width and height;\n",
    "+ Still need to understand if they actually use transpose convolution or (as it is written) an upsampling then normal conv;\n",
    "+ Still need to write backward pass and sample training\n",
    "+ For now, I made a little modification: 2x2 convolution for upscaling has been replaced with 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(UNET, self).__init__()\n",
    "    \t# encoding part of the Unet vanilla architecture\n",
    "\t\tself.encode1 = nn.Sequential(\n",
    "\t\t\tUnetEncodeLayer(3, 64),\n",
    "\t\t\tUnetEncodeLayer(64, 64),\n",
    "\t\t)\n",
    "\t\tself.encode2 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(64, 128),\n",
    "\t\t\tUnetEncodeLayer(128, 128),\n",
    "\t\t)\n",
    "\t\tself.encode3 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(128, 256),\n",
    "\t\t\tUnetEncodeLayer(256, 256),\n",
    "\t\t)\n",
    "\t\tself.encode4 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(256, 512),\n",
    "\t\t\tUnetEncodeLayer(512, 512),\n",
    "\t\t)\n",
    "\t\tself.encode5 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(512, 1024),\n",
    "\t\t\tUnetEncodeLayer(1024, 1024),\n",
    "\t\t)\t\t\n",
    "\t\tself.decode1 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2, 1024)\n",
    "\t\t)\n",
    "\t\tself.decode_forward1 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(1024,512)\n",
    "\t\t)\n",
    "\t\tself.decode2 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,512)\n",
    "\t\t)\n",
    "\t\tself.decode_forward2 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(512, 256)\n",
    "\t\t)\n",
    "\t\tself.decode3 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,256)\n",
    "\t\t)\n",
    "\t\tself.decode_forward3 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(256,128)\n",
    "\t\t)\n",
    "\t\tself.decode4 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,128)\n",
    "\t\t)\n",
    "\t\tself.decode_forward4 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(128,64),\n",
    "\t\t\tnn.Conv2d(64, 2, kernel_size=1) # final conv 1x1\n",
    "\t\t)\t\n",
    "\tdef forward(self, x: torch.Tensor):\n",
    "\t\tx1 = self.encode1(x)\n",
    "\t\tres1 = functional.center_crop(x1, 392)\n",
    "\t\tx2 = self.encode2(x1)\n",
    "\t\tres2 = functional.center_crop(x2,200)\n",
    "\t\tx3 = self.encode3(x2)\n",
    "\t\tres3 = functional.center_crop(x3,104)\n",
    "\t\tx4 = self.encode4(x3)\n",
    "\t\tres4 = functional.center_crop(x4, 56)\n",
    "\t\tx5 = self.encode5(x4)\n",
    "\n",
    "\t\ty1 = self.decode1(x5)\n",
    "\t\tc1 = torch.concat((res4, y1), 1)\n",
    "\t\ty2 = self.decode_forward1(c1)\n",
    "\n",
    "\t\ty2 = self.decode2(y2)\n",
    "\t\tc2 = torch.concat((res3, y2), 1)\n",
    "\t\ty3 = self.decode_forward2(c2)\n",
    "\n",
    "\t\ty3 = self.decode3(y3)\n",
    "\t\tc3 = torch.concat((res2, y3),1)\n",
    "\t\ty4 = self.decode_forward3(c3)\n",
    "\t\t\n",
    "\t\ty4 = self.decode4(y4)\n",
    "\t\tc4 = torch.concat((res1, y4), 1)\n",
    "\n",
    "\t\tseg_map = self.decode_forward4(c4)\t\t\n",
    "\n",
    "\t\treturn c4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Urnet(nn.Module):\t\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Urnet, self).__init__()\n",
    "\t\tself.residuals = []\n",
    "    \t# encoding part of the Unet vanilla architecture\n",
    "\t\tself.encode1 = nn.Sequential(\n",
    "\t\t\tUnetEncodeLayer(3, 64, padding=1),\n",
    "\t\t\tUnetEncodeLayer(64, 64, padding=1), ## keep dimensions unchanged\n",
    "\t\t)\n",
    "\t\tself.encode2 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(64, 128, padding=1),\n",
    "\t\t\tUnetEncodeLayer(128, 128, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode3 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\t\t\tUnetEncodeLayer(128, 256, padding=1),\n",
    "\t\t\tUnetEncodeLayer(256, 256, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode4 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(256, 512, padding=1),\n",
    "\t\t\tUnetEncodeLayer(512, 512, padding=1),\n",
    "\t\t)\n",
    "\t\tself.encode5 = nn.Sequential(\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tUnetEncodeLayer(512, 1024, padding=1),\n",
    "\t\t\tUnetEncodeLayer(1024, 1024, padding=1),\n",
    "\t\t)\n",
    "\t\tself.upscale1 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2, 1024)\n",
    "\t\t)\n",
    "\t\tself.decode_forward1 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(1024,512, padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale2 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2, 512)\n",
    "\t\t)\n",
    "\t\tself.decode_forward2 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(512, 256, padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale3 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,256)\n",
    "\t\t)\n",
    "\t\tself.decode_forward3 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(256,128,padding=1)\n",
    "\t\t)\n",
    "\t\tself.upscale4 = nn.Sequential(\n",
    "\t\t\tUnetUpscaleLayer(2,128)\n",
    "\t\t)\n",
    "\t\tself.decode_forward4 = nn.Sequential(\n",
    "\t\t\tUnetForwardDecodeLayer(128,64, padding=1),\n",
    "\t\t\tnn.Conv2d(64, 3, kernel_size=1) # final conv 1x1\n",
    "\t\t)\t\n",
    "\tdef forward(self, x: torch.Tensor):\n",
    "\t\tself.x1 = self.encode1(x)\n",
    "\t\tself.x2 = self.encode2(self.x1)\n",
    "\t\tself.x3 = self.encode3(self.x2)\n",
    "\t\tself.x4 = self.encode4(self.x3)\n",
    "\t\tself.x5 = self.encode5(self.x4)\n",
    "\n",
    "\t\ty1 = self.upscale1(self.x5)\n",
    "\t\tc1 = torch.concat((self.x4, y1), 1)\n",
    "\t\ty2 = self.decode_forward1(c1)\n",
    "\t\t\n",
    "\t\ty2 = self.upscale2(y2)\n",
    "\t\tc2 = torch.concat((self.x3, y2), 1)\n",
    "\t\ty3 = self.decode_forward2(c2)\n",
    "\n",
    "\t\ty3 = self.upscale3(y3)\n",
    "\t\tc3 = torch.concat((functional.center_crop(y3, 150), self.x2), 1)\n",
    "\t\ty4 = self.decode_forward3(c3)\n",
    "\n",
    "\t\ty4 = self.upscale4(y4)\n",
    "\t\tc4 = torch.concat((self.x1, y4), 1)\n",
    "\t\tsegmap = self.decode_forward4(c4)\n",
    "\t\treturn segmap\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters : 34513475\n"
     ]
    }
   ],
   "source": [
    "net = Urnet()  # instantiate your net\n",
    "num_params = sum([np.prod(p.shape) for p in net.parameters()])\n",
    "print(f\"Number of parameters : {num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class PostDamDataset(Dataset):\n",
    "\tdef __init__(self, img_dir, masks_dir):\n",
    "\t\tself.idir = img_dir\n",
    "\t\tself.mdir = masks_dir\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(os.listdir(self.idir))\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.idir, \"Image_{}.tif\".format(idx))\n",
    "\t\tmask_path = os.path.join(self.mdir, \"Label_{}.tif\".format(idx))\n",
    "\t\ttif_img = Image.open(img_path)\n",
    "\t\ttif_mask = Image.open(mask_path)\n",
    "\t\treturn ToTensor()(tif_img), ToTensor()(tif_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset = PostDamDataset(\"C:\\\\Users\\\\web\\\\Desktop\\\\CVCS\\\\dataset\\\\Postdam\\\\Images\", \"C:\\\\Users\\\\web\\\\Desktop\\\\CVCS\\\\dataset\\\\Postdam\\\\Labels\")\n",
    "# img,mask = dataset.__getitem__(12)\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,sampler=valid_sampler)\n",
    "num_epochs = 10\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):    \n",
    "    pbar = tqdm(total=len(train_loader), desc=f'Epoch {epoch}')\n",
    "    net.train()\n",
    "    for batch_index, (image, mask) in enumerate(train_loader):\n",
    "        mask_pred = net(image)\n",
    "        loss = crit(mask_pred, mask)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'Loss': loss.item()})\n",
    "    pbar.close()\n",
    "    with torch.no_grad():\n",
    "        net.eval()        \n",
    "        for image, mask in validation_loader:\n",
    "            mask_pred = net(image)\n",
    "            plt.imshow(mask_pred.swapaxes(0,2))\n",
    "            plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
